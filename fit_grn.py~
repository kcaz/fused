import numpy as np
import fused_reg as fl
import data_sources as ds
import random
from sklearn.metrics import roc_curve, auc, precision_recall_curve
import os
import collections
#SECTION: ------------------UTILITY FUNCTIONS-----------------




#SECTION: ------------------FOR RUNNING BACTERIAL DATA



def fit_model(data_fn, lamP, lamR, lamS, solver='solve_ortho_direct',special_args=None):
    ds1 = ds.standard_source(data_fn,0)
    ds2 = ds.standard_source(data_fn,1)
    orth_fn = os.path.join(data_fn, 'orth')

    organisms = [ds1.name, ds2.name]
    orth = ds.load_orth(orth_fn, organisms)

    
    (priors1, signs1) = ds1.get_priors()
    (priors2, signs2) = ds2.get_priors()

    (e1_tr, t1_tr, genes1, tfs1) = ds1.load_data()
    (e2_tr, t2_tr, genes2, tfs2) = ds2.load_data()

        # jam things together
    Xs = [t1_tr, t2_tr]
    Ys = [e1_tr, e2_tr]
    
    genes = [genes1, genes2]
    tfs = [tfs1, tfs2]
    priors = priors1 + priors2

    if solver == 'solve_ortho_direct':
        Bs = fl.solve_ortho_direct(organisms, genes, tfs, Xs, Ys, orth, priors, lamP, lamR, lamS)
    if solver == 'solve_ortho_direct_scad':
        Bs = fl.solve_ortho_direct_scad(organisms, genes, tfs, Xs, Ys, orth, priors, lamP, lamR, lamS, s_it = special_args['s_it'], special_args = special_args)
    if solver == 'solve_ortho_ref':
        Bs = fl.solve_ortho_ref(organisms, genes, tfs, Xs, Ys, orth, priors, lamP, lamR, lamS)
    
    return Bs


#this is the master cross-validator!
def cv_model_m(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True, pct_priors=0, seed=None, verbose=False):
    if seed != None:
        random.seed(seed)

    ds1 = ds.standard_source(data_fn,0)
    ds2 = ds.standard_source(data_fn,1)
    dss = [ds1, ds2]

    #set up containers for results
    metrics = ['mse','R2','aupr','auc','corr', 'auc_con','aupr_con']
    err_dict1 = {m : np.zeros((k, 1)) for m in metrics}
    err_dict2 = {m : np.zeros((k, 1)) for m in metrics}
    err_dicts = [err_dict1, err_dict2] #for indexing


    (constraints, marks, orth) = ds.load_constraints(data_fn)
    
    orth_fn = os.path.join(data_fn, 'orth')

    organisms = [ds1.name, ds2.name]
    orth = ds.load_orth(orth_fn, organisms)
    
    folds = [ds1.partition_data(k), ds2.partition_data(k)]
    
    (priors1, signs1) = ds1.get_priors()
    (priors2, signs2) = ds2.get_priors()

    #helper to return all but ith entry of list x    
    excl = lambda x,i: x[0:i]+x[(i+1):] 
    
    #helper function for dividing priors
    def r_partition(x, t):
        inds = np.arange(len(x))
        random.shuffle(inds)
        p1 = map(lambda i: x[i], inds[0:t])
        p2 = map(lambda i: x[i], inds[t:])
        return (p1, p2)
    print pct_priors
    (priors1_tr, priors1_te) = r_partition(priors1, int(pct_priors*len(priors1)))
    (priors2_tr, priors2_te) = r_partition(priors2, int(pct_priors*len(priors2)))

    priors_tr = [priors1_tr, priors2_tr]
    priors_te = [priors1_te, priors2_te]

    f_te = [None, None]
    f_tr = [None, None]
    genes = [None, None]
    tfs = [None, None]
    Xs = [None, None]
    Ys = [None, None]
    Xs_te = [None, None]
    Ys_te = [None, None]
    for fold in range(k):
        if verbose:
            print 'working on %d' % fold
        #get conditions for current cross-validation fold
        for si in (0,1):
            if cv_both[si]:
                f_te[si] = folds[si][fold]
                f_tr[si] = np.hstack(excl(folds[si], fold))    
            if reverse:
                tmp = f_tr[si]
                f_tr[si] = f_te[si]
                f_te[si] = tmp
            (e_tr, t_tr, genes_si, tfs_si) = dss[si].load_data(f_tr[si])
            (e_te, t_te, genes_si, tfs_si) = dss[si].load_data(f_te[si])

            Xs[si] = t_tr
            Xs_te[si] = t_te

            Ys[si] = e_tr
            Ys_te[si] = e_te

            genes[si] = genes_si
            tfs[si] = tfs_si

        priors_tr_fl = priors_tr[0] + priors_tr[1]
        #solve the model
        if solver == 'solve_ortho_direct':
            Bs = fl.solve_ortho_direct(organisms, genes, tfs, Xs, Ys, orth, priors_tr_fl, lamP, lamR, lamS)
        if solver == 'solve_ortho_direct_scad':
            Bs = fl.solve_ortho_direct_scad(organisms, genes, tfs, Xs, Ys, orth, priors_tr_fl, lamP, lamR, lamS, s_it = special_args['s_it'], special_args=special_args)
        if solver == 'solve_ortho_direct_mcp':
            Bs = fl.solve_ortho_direct_mcp(organisms, genes, tfs, Xs, Ys, orth, priors_tr_fl, lamP, lamR, lamS, m_it = special_args['m_it'], special_args=special_args)
        if solver == 'solve_ortho_direct_em':
            Bs = fl.solve_ortho_direct_em(organisms, genes, tfs, Xs, Ys, orth, priors_tr_fl, lamP, lamR, lamS, em_it = special_args['em_it'], special_args=special_args)

         #evaluate a bunch of metrics
        (corr, fused_coeffs) = fused_coeff_corr(organisms, genes, tfs, orth, Bs)
        for si in [0,1]:
            err_dicts[si]['corr'][fold,0] = corr

            mse = prediction_error(Xs_te[si], Bs[si], Ys_te[si], 'mse', exclude_tfs=exclude_tfs)
            err_dicts[si]['mse'][fold, 0] = mse

            R2 = prediction_error(Xs_te[si], Bs[si], Ys_te[si], 'R2', exclude_tfs=exclude_tfs)
            err_dicts[si]['R2'][fold, 0] = R2

            
            aupr = eval_network_pr(Bs[si], genes[si], tfs[si], priors_te[si], exclude_tfs=exclude_tfs, constraints = None)
            err_dicts[si]['aupr'][fold,0] = aupr
            
            aupr_con = eval_network_pr(Bs[si], genes[si], tfs[si], priors_te[si], exclude_tfs=exclude_tfs, constraints = constraints, sub = si)
            err_dicts[si]['aupr_con'][fold,0] = aupr_con                

            auc = eval_network_roc(Bs[si], genes[si], tfs[si], priors_te[si], exclude_tfs=exclude_tfs, constraints = None)
            err_dicts[si]['auc'][fold,0] = aupr
            
            auc_con = eval_network_roc(Bs[si], genes[si], tfs[si], priors_te[si], exclude_tfs=exclude_tfs, constraints = constraints, sub = si)
            err_dicts[si]['auc_con'][fold,0] = aupr_con                
    return err_dicts


#runs the basic model with specified parameters under k-fold cross-validation, and stores a number of metrics
#k: the number of cv folds
#reverse: train on the little dude (reverse train and test)
#cv_both: if false, always use all the data for the corresponding species
#exclude_tfs: don't evaluate on transcription factors. this is useful for generated data, where you can't hope to get them right
def cv_model1(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True, eval_con=False):
    print 'DEPRACATED cv_model1'


#runs the basic model with specified parameters under k-fold cross-validation, and stores a number of metrics
#returns array for plotting in seaborn
#k: the number of cv folds
#reverse: train on the little dude (reverse train and test)
#cv_both: if false, always use all the data for the corresponding species
#exclude_tfs: don't evaluate on transcription factors. this is useful for generated data, where you can't hope to get them right
def cv_model2(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True):
    print 'DEPRACATED cv_model2'
    


#runs the basic model with specified parameters under k-fold cross-validation
#stores a bunch of metrics, applied to each CV-fold
#k: the number of cv folds
#reverse: train on the little dude (reverse train and test)
#cv_both: if false, always use all the data for the corresponding species
#exclude_tfs: don't evaluate on transcription factors. this is useful for generated data, where you can't hope to get them right
#doesn't output any files
def cv_model3(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True):
    print 'DEPRACATED cv_model3'


#cv_model3, but with pct_priors
def cv_model4(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True, pct_priors=0):
    print 'DEPRACATED cv_model4'

#cv_model1, but with percent_priors
#runs the basic model with specified parameters under k-fold cross-validation, and stores a number of metrics
#percent_priors is the percent of priors to use. these priors are removed from the test set
#k: the number of cv folds
#reverse: train on the little dude (reverse train and test)
#cv_both: if false, always use all the data for the corresponding species
#exclude_tfs: don't evaluate on transcription factors. this is useful for generated data, where you can't hope to get them right
def cv_model5(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True, eval_con=False, pct_priors=0):
    print 'DEPRACATED cv_model5'

#SECTION: -------------------------CODE FOR EVALUATING THE OUTPUT

#model prediction error, using one of several metrics
#exclude_tfs doesn't evaluate predictions of the tfs, and assumes that TFs come before all other genes.
def prediction_error(X, B, Y, metric, exclude_tfs = True):
    Ypred = np.dot(X, B)
    y = Y[:,0]
    yp = Ypred[:,0]
    num_tfs = B.shape[0]
    if exclude_tfs:
        start_ind = num_tfs
    else:
        start_ind = 0
    
    if metric == 'R2':
        r2a = 0.0
        from matplotlib import pyplot as plt
        for c in range(start_ind, Ypred.shape[1]):
            y = Y[:, c]
            yp = Ypred[:, c]
            r2 = 1 - ((y-yp)**2).sum()/ ((y-y.mean())**2).sum()
            r2a += r2
            
#            if c == start_ind:
#                plt.plot(y)
#                plt.plot(yp)
#                plt.show()
        return r2a/(Ypred.shape[1]-start_ind)
    if metric == 'mse':
        msea = 0.0
        for c in range(start_ind, Ypred.shape[1]):
            y = Y[:, c]
            yp = Ypred[:, c]
            mse = ((y-yp)**2).mean()
            msea += mse

        return msea / (Ypred.shape[1]-start_ind)
    if metric == 'corr':
        corra = 0.0
        for c in range(start_ind, Ypred.shape[1]):
            y = Y[:, c]
            yp = Ypred[:, c]
            corr = np.corrcoef(y, yp)[0,1]
            corra += corr
        return corra / (Ypred.shape[1] - start_ind)

#evaluates the area under the precision recall curve, with respect to some given priors
# exclude_tfs: do not evaluate on tf x tf interactions
# constraints: if not None, evaluates only on interactions which have fusion constraints
#sub: name of subproblem. used if constraints != None
def eval_network_pr(net, genes, tfs, priors, exclude_tfs = False, constraints = None, sub=None):
    #from matplotlib import pyplot as plt
    if len(priors) == 0:
        return np.nan
    org = priors[0][0].organism
    priors_set = set(priors)
    gene_to_ind = {genes[x] : x for x in range(len(genes))}
    
    tf_to_ind = {tfs[x] : x for x in range(len(tfs))}
    gene_marked = np.zeros(len(genes)) != 0
    tf_marked = np.zeros(len(tfs)) != 0
    if constraints != None:
        con_set = set()
        for con in constraints:    
            if con.c1.sub == sub:
                con_set.add(con.c1)
            if con.c2.sub == sub:
                con_set.add(con.c2)
        
    #we only evaluate on interactions when the gene/tf is mentioned in a prior
    for prior in priors:
        
        gene_marked[gene_to_ind[prior[0].name]] = True
        gene_marked[gene_to_ind[prior[1].name]] = True
        if prior[0].name in tf_to_ind:
            tf_marked[tf_to_ind[prior[0].name]] = True
        if prior[1].name in tf_to_ind:
            tf_marked[tf_to_ind[prior[1].name]] = True

    genes = np.array(genes)[gene_marked]
    tfs = np.array(tfs)[tf_marked]
    net = net[:, gene_marked]
    net = net[tf_marked, :]
    scores = []#np.zeros(len(genes)*len(tfs))
    labels = []#np.zeros(len(genes)*len(tfs))
    i=0
    for tfi in range(len(tfs)):
        for gi in range(len(genes)):
            if exclude_tfs and gi < len(tfs):
                continue
            if constraints != None:
                coeff = fl.coefficient(sub=sub, r=tfi, c=gi) #potential coefficient
                
                if not coeff in con_set:
                    continue

            tf = tfs[tfi]
            g = genes[gi]
            score = np.abs(net[tfi, gi])
            label = 0
            if (fl.one_gene(tf, org), fl.one_gene(g, org)) in priors_set:
                label = 1
            if (fl.one_gene(g, org), fl.one_gene(tf, org)) in priors_set:
                label = 1
            
            
            scores.append(score)#scores[i] = score
            labels.append(label)#labels[i] = label
    if len(scores):
            
        (precision, recall,t) = precision_recall_curve(labels, scores)#prc(scores, labels)
        aupr = auc(recall, precision)
    else:
        aupr = np.nan
    
    return aupr

#evaluates the area under the roc, with respect to some given priors

def eval_network_roc(net, genes, tfs, priors, exclude_tfs = True, constraints = None, sub=None):
    if len(priors) == 0:
        return np.nan
    org = priors[0][0].organism
    priors_set = set(priors)
    scores = []#np.zeros(len(genes)*len(tfs))
    labels = []#np.zeros(len(genes)*len(tfs))
    i=0
    if constraints != None:
        con_set = set()
        for con in constraints:
            if con.c1.sub == sub:
                con_set.add(con.c1)
            if con.c2.sub == sub:
                con_set.add(con.c2)
        
    for tfi in range(len(tfs)):
        for gi in range(len(genes)):
            if exclude_tfs and gi < len(tfs):
                continue
            if constraints != None:
                coeff = fl.coefficient(sub=sub, r=tfi, c=gi) #potential coefficient

                if not coeff in con_set:
                    continue

            tf = tfs[tfi]
            g = genes[gi]
            score = np.abs(net[tfi, gi])
            label = 0
            
            
            if (fl.one_gene(tf, org), fl.one_gene(g, org)) in priors_set:
                label = 1
            if (fl.one_gene(g, org), fl.one_gene(tf, org)) in priors_set:
                label = 1
            scores.append(score)
            labels.append(label)            
            i += 1

    if len(scores):
        (fpr, tpr, t) = roc_curve(labels, scores)
        if any(np.isnan(fpr)) or any(np.isnan(tpr)):
            return 0.0 #no false positives        
        auroc = auc(fpr, tpr)
    else:
        auroc = np.nan

    return auroc

def eval_network_beta(net1, net2):
    return ((net1 - net2)**2).mean()
            
#generates fusion constraints, then computes the correlation between fused coefficients
def fused_coeff_corr(organisms, genes_l, tfs_l, orth, B_l):
    constraints = fl.orth_to_constraints(organisms, genes_l, tfs_l, orth, 1.0)
    fused_vals = [[],[]]
    
    if len(constraints) == 0:
        return (np.nan, np.zeros((2,0)))
    for con in constraints:
        s1 = con.c1.sub
        b1 = B_l[s1][con.c1.r, con.c1.c]
        s2 = con.c2.sub
        b2 = B_l[s2][con.c2.r, con.c2.c]
        fused_vals[s1].append(b1)
        fused_vals[s2].append(b2)
    fused_vals = np.array(fused_vals)
    return (np.corrcoef(fused_vals)[0,1], fused_vals)

#take list of lamP, lamR, lamS values and finds the optimal parameters using cv_model1
def grid_search_params(data_fn, lamP, lamR, lamS, k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True, eval_metric='mse'):

    seed = random.random()
    grid = dict()
    best_mse = 1000
    best_R2 = 0
    best_aupr = 0
    best_auroc = 0
    best_lamP = 1.0
    best_lamR = 0
    best_lamS = 0
    for r in range(len(lamR)):
        for s in range(len(lamS)):
            for p in range(len(lamP)):
                (errd1, errd2) = cv_model_m(data_fn, lamP[p], lamR[r], lamS[s], k, solver='solve_ortho_direct',special_args=None, reverse=False, cv_both=(True,True), exclude_tfs=True, seed=seed, verbose=True)

                if eval_metric == 'mse':
                    grid[str(lamR[r])+'_'+str(lamS[s])+'_'+str(lamP[p])] = errd1['mse']
                    score = errd1['mse'].mean()
                    if score < best_mse:
                        best_mse = score
                        best_lamP = lamP[p]
                        best_lamR = lamR[r]
                        best_lamS = lamS[s]
                if eval_metric == 'R2':
                    grid[str(lamR[r])+'_'+str(lamS[s])+'_'+str(lamP[p])] = errd1['R2']   
                    score = errd1['R2'].mean()
                    if score > best_R2:
                        best_R2 = score
                        best_lamP = lamP[p]
                        best_lamR = lamR[r]
                        best_lamS = lamS[s]
                if eval_metric == 'aupr':
                    grid[str(lamR[r])+'_'+str(lamS[s])+'_'+str(lamP[p])] = errd1['aupr']
                    score = errd1['aupr'].mean()
                    if score > best_aupr:
                        best_aupr = score
                        best_lamP = lamP[p]
                        best_lamR = lamR[r]
                        best_lamS = lamS[s]
                if eval_metric == 'auroc':
                    grid[str(lamR[r])+'_'+str(lamS[s])+'_'+str(lamP[p])] = errd1['auroc']
                    score = errd1['auroc'].mean()
                    if score > best_auroc:
                        best_auroc = score
                        best_lamP = lamP[p]
                        best_lamR = lamR[r]
                        best_lamS = lamS[s]
    if eval_metric == 'mse':
        return (best_mse, best_lamP, best_lamR, best_lamS, grid)
    if eval_metric == 'R2':
        return (best_R2, best_lamP, best_lamR, best_lamS, grid)
    if eval_metric == 'aupr':
        return (best_aupr, best_lamP, best_lamR, best_lamS, grid)
    if eval_metric == 'auroc':
        return (best_auroc, best_lamP, best_lamR, best_lamS, grid)

